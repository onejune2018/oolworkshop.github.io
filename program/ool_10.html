---
layout: paper
id: 10
slides_live_id: 1
rocket_id: ool-paper-10
meeting_url: https://us04web.zoom.us/j/79966325785
authors: "Wilka Carvalho, Anthony Liang, Kimin Lee, Sungryull Sohn, Honglak Lee, Richard L Lewis, and Satinder Singh"
camera_ready: true
cmt_id: 10
kind: poster
session_id: 2
session_title: "Session 2 (11:00-11:59pm UTC)"
title: "ROMA: A Relational Object Modeling Agent for Sample-Efficient Reinforcement Learning"
abstract: "Sequential decision-making tasks that require relating and using multiple novel objects pose significant sample-efficiency challenges for agents learning from sparse task rewards. In this work, we begin to address these challenges by leveraging an agent's object-interactions to define an auxilliary task that enables sample-efficient reinforcement learning (RL) of tasks centered around object-interactions. To accomplish this, we formulate ROMA: a relational reinforcement learning agent that learns an object-centric forward model during task learning. We find that this enables it to learn object-interaction tasks much faster than other relational RL agents with alternative auxiliary tasks for driving the learning of good representations. In order to evaluate the performance of our agent, we introduce a set of object-interaction tasks in the AI2Thor virtual home environment that require relating and interacting with multiple objects. By comparing against an agent equipped with ground-truth object-information, we find that learning an object-centric forward model best closes the performance gap, achieving >=80% of its sample-efficiency on 7 out of 8 tasks, with the next best method doing so on 2 out of 8 tasks."
track: research
live: false
video_file_url: https://github.com/oolworkshop/oolworkshop.github.io/blob/master/poster_videos/10.mp4.zip?raw=true
youtube_url: https://youtu.be/wed082iOexo
---