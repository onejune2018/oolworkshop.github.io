---
layout: paper
id: 7
slides_live_id: 38930705
rocket_id: ool-paper-7
meeting_url: https://us04web.zoom.us/j/77611452718
authors: "Yizhe Wu, Sudhanshu Kasewa, Oliver M Groth, Sasha Salter, Li Sun, Oiwi Parker Jones, and Ingmar Posner"
camera_ready: true
cmt_id: 7
kind: oral
session_id: 1
session_title: "Session 1 (3:30-4:30pm UTC)"
title: "Learning Affordances in Object-Centric Generative Models"
abstract: "Given visual observations of a reaching task together with a stick-like tool, we propose a novel approach that learns to exploit task-relevant object affordances by combining generative modelling with a task-based performance predictor. The embedding learned by the generative model captures the factors of variation in object geometry, e.g. length, width, and configuration. The performance predictor identifies sub-manifolds correlated with task success in a weakly supervised manner. Using a 3D simulation environment, we demonstrate that traversing the latent space in this task-driven way results in appropriate tool geometries for the task at hand. Our results suggest that affordances are encoded along smooth trajectories in the learned latent space. Given only high-level performance criteria (such as task success), accessing these emergent affordances via gradient descent enables the agent to manipulate learned object geometries in a targeted and deliberate way."
track: research
live: false
video_file_url: none
youtube_url: none
---