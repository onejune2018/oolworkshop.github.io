- abstract: Recently, there has been a surge of interest for object-centric learning
    in neural network research. To many researchers, it seems clear that objects hold
    great potential for enabling more systematic generalisation, building compositional
    models of the world, and as grounding for language and symbolic reasoning. However,
    despite strong intuitions, a general definition of what constitutes an object
    is still lacking, and the precise notion of objects remains largely elusive. In
    this talk I aim to challenge some common intuitive conceptions about objects,
    and point to some of their subtle complexity. After that, I will present a few
    relevant findings from cognitive psychology regarding human object perception,
    and conclude by discussing a few challenges and promising approaches for incorporating
    objects into neural networks.
  authors: Klaus Greff
  id: 34
  kind: oral
  title: What are Objects
- abstract: To enable explicit representation of objects in neural architectures,
    a core challenge lies in defining a mapping from input features (e.g., an image
    encoded by a CNN) to a set of abstract object representations. In this talk, I
    will discuss how attention mechanisms can be used in an iterative, competitive
    fashion to (a) efficiently group visual features into object slots and (b) segment
    temporal representations. I will further highlight how graph neural networks can
    be utilized to learn about interactions between objects and how object-centric
    models can be trained in a self-supervised fashion using contrastive losses.
  authors: Thomas Kipf
  id: 35
  kind: oral
  title: Attentive Grouping and Graph Neural Networks for Object-Centric Learning
- abstract: Understanding causes and effects in mechanical systems is an essential
    component of reasoning in the physical world. This work poses a new problem of
    counterfactual learning of object mechanics from visual input. We develop the
    CoPhy benchmark to assess the capacity of the state-of-the-art models for causal
    physical reasoning in a synthetic 3D environment and propose a model for learning
    the physical dynamics in a counterfactual setting. Having observed a mechanical
    experiment that involves, for example, a falling tower of blocks, a set of bouncing
    balls or colliding objects, we learn to predict how its outcome is affected by
    an arbitrary intervention on its initial conditions, such as displacing one of
    the objects in the scene. The alternative future is predicted given the altered
    past and a latent representation of the confounders learned by the model in an
    end-to-end fashion with no supervision. We compare against feedforward video prediction
    baselines and show how observing alternative experiences allows the network to
    capture latent physical properties of the environment, which results in significantly
    more accurate predictions at the level of super human performance.
  authors: Fabien Baradel
  id: 36
  kind: oral
  title: Object-level video understanding
- abstract: Two-dimensional images are commonly used to study and model perceptual
    and cognitive processes because of the convenience and ease of experimental control
    they provide. However, real objects differ from pictures in many ways, including
    the potential for interaction and richer information about distance and thus size.
    Across a series of neuroimaging studies and behavioral experiments in adults,
    we have shown different responses to real objects than pictures. Moreover, we
    have found behavioral differences between real objects and pictures even in infants,
    suggesting that realness plays an important role in learning about objects. These
    results can inform the next generation of computational models as to how human
    brains learn to process objects in the real world.
  authors: Jody Culham
  id: 37
  kind: oral
  title: '"The treachery of images": How the realness of objects affects brain activation
    and behavior'
- abstract: "Objects elicit attention in many everyday contexts, even from infancy.\
    \ Objects also serve as the referents for humans\u2019 earliest symbolic learning:\
    \ language. In this talk, I\u2019ll present my lab\u2019s recent work with young\
    \ children suggesting that objects are also prioritized in another early emerging\
    \ and uniquely human symbolic expression: drawing.  I\u2019ll conclude my talk\
    \ by suggesting that researchers interested in artificial intelligence may look\
    \ for inspiration in human intelligence, especially when it comes to the way that\
    \ humans attend to and represent objects."
  authors: Moira Dillon
  id: 38
  kind: oral
  title: Object-Oriented Drawings
- abstract: Learning depends on both the learning mechanism and the structure of the
    training data, yet most research in human learning and efforts in machine learning
    concentrate on the learning mechanisms.  I will present evidence on the everyday-day
    ego-centric visual experiences of infants.  The regularities differ fundamentally
    and in  multiple inter-related from current approaches to training in machine
    learning and perhaps will offer inspiration to more powerful, more incremental,
    and more autonomous machine learning.
  authors: Linda Smith
  id: 39
  kind: oral
  title: Learning from an infant's point of view
- abstract: 'How we represent signals has major implications for the algorithms we
    build to analyze them. Today, most signals are represented discretely: Images
    as grids of pixels, shapes as point clouds, audio as grids of amplitudes, etc.
    If images weren''t pixel grids - would we be using convolutional neural networks
    today? What makes a good or bad representation? Can we do better? I will talk
    about leveraging emerging implicit neural representations for complex & large
    signals, such as room-scale geometry, images, audio, video, and physical signals
    defined via partial differential equations. By embedding an implicit scene representation
    in a neural rendering framework and learning a prior over these representations,
    I will show how we can enable 3D reconstruction from only a single posed 2D image.
    Finally, I will show how gradient-based meta-learning can enable fast inference
    of implicit representations, and how the features we learn in the process are
    already useful to the downstream task of semantic segmentation.'
  authors: Vincent Sitzmann
  id: 40
  kind: oral
  title: Implicit Neural Scene Representations
- abstract: Energy-based models are undergoing a resurgence of interest, but their
    applications have largely focused on generative modeling and density estimation.
    In this talk I will discuss application of energy-based models to object or concept
    oriented learning and reasoning. These models offer an elegant approach to concept
    composition, continual and unsupervised learning, and usage of concepts in multiple
    contexts. I will show examples of these advantages, and conclude with a set of
    future research directions.
  authors: Igor Mordatch
  id: 41
  kind: oral
  title: Energy-Based Models for Object-Oriented Learning
